"""
Inference Script for C2P + SVD Detector (BATCH VERSION - NO TEXT GUIDANCE)
æ”¯æŒå•å¼ å›¾åƒå’Œæ‰¹é‡æ–‡ä»¶å¤¹æŽ¨ç†ï¼Œè‡ªåŠ¨å¤„ç†æƒé‡ä¸åŒ¹é…é—®é¢˜

æ–°å¢žåŠŸèƒ½ï¼š
1. è‡ªåŠ¨è¯†åˆ«è¾“å…¥ç±»åž‹ï¼ˆæ–‡ä»¶/æ–‡ä»¶å¤¹ï¼‰
2. æ‰¹é‡å¤„ç†å¤šå¼ å›¾åƒ
3. ç»“æžœä¿å­˜ä¸ºCSV
4. è¯¦ç»†ç»Ÿè®¡ä¿¡æ¯
5. å®½æ¾æƒé‡åŠ è½½ï¼ˆå¿½ç•¥è®­ç»ƒæ—¶çš„æ–‡æœ¬å¼•å¯¼å‚æ•°ï¼‰
"""

import os
import argparse
import torch
import torch.nn.functional as F
from PIL import Image
from torchvision import transforms
from tqdm import tqdm
import pandas as pd
from pathlib import Path

from c2p_svd_detector import C2P_SVD_Detector


def parse_args():
    parser = argparse.ArgumentParser(description='Inference with C2P+SVD (Batch Support)')
    parser.add_argument('--checkpoint', type=str, required=True,
                        help='Path to trained model checkpoint')
    
    parser.add_argument('--input', type=str, required=True,
                        help='Path to input image or folder')
    
    parser.add_argument('--output', type=str, default=None,
                        help='Output CSV file for batch results (auto-generated if not specified)')
    
    parser.add_argument('--device', type=str, default='cuda',
                        help='Device to use (cuda/cpu)')
    
    parser.add_argument('--svd_rank', type=int, default=1023,
                        help='SVD rank used during training (default: 1023)')
    
    parser.add_argument('--recursive', action='store_true',
                        help='Recursively search subdirectories for images')
    
    parser.add_argument('--save_details', action='store_true',
                        help='Save detailed per-image results to separate text files')
    
    return parser.parse_args()


def load_model(checkpoint_path, svd_rank, device):
    """
    åŠ è½½è®­ç»ƒå¥½çš„æ¨¡åž‹ï¼ˆå®½æ¾åŠ è½½ç‰ˆæœ¬ï¼Œè‡ªåŠ¨å¤„ç†æƒé‡ä¸åŒ¹é…ï¼‰
    
    Args:
        checkpoint_path: æ£€æŸ¥ç‚¹æ–‡ä»¶è·¯å¾„
        svd_rank: SVDç§©ï¼ˆå¿…é¡»ä¸Žè®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        device: è®¾å¤‡
    
    Returns:
        model: åŠ è½½å¥½çš„æ¨¡åž‹
        checkpoint: æ£€æŸ¥ç‚¹å­—å…¸ï¼ˆåŒ…å«è®­ç»ƒä¿¡æ¯ï¼‰
    """
    print(f"\nðŸ”„ Loading checkpoint: {checkpoint_path}")
    
    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"Checkpoint not found: {checkpoint_path}")
    
    checkpoint = torch.load(checkpoint_path, map_location=device)
    
    # æ‰“å°æ£€æŸ¥ç‚¹ä¿¡æ¯
    print(f"  âœ“ Checkpoint loaded")
    print(f"    - Epoch: {checkpoint.get('epoch', 'Unknown')}")
    print(f"    - Val AUC: {checkpoint.get('val_auc', 0.0):.4f}")
    print(f"    - Val Acc: {checkpoint.get('val_acc', 0.0):.4f}")
    
    # åˆå§‹åŒ–æŽ¨ç†æ¨¡åž‹ï¼ˆä¸ä½¿ç”¨æ–‡æœ¬å¼•å¯¼ï¼‰
    print(f"\nðŸ”§ Initializing inference model (SVD rank: {svd_rank})")
    print(f"    - Text guidance: DISABLED (inference mode)")
    
    model = C2P_SVD_Detector(
        clip_model_name='openai/clip-vit-large-patch14',
        num_classes=2,
        svd_rank=svd_rank,
        use_text_guidance=False  # æŽ¨ç†æ—¶ä¸éœ€è¦æ–‡æœ¬å¼•å¯¼
    ).to(device)
    
    # â˜… å®½æ¾åŠ è½½æƒé‡ - è‡ªåŠ¨è¿‡æ»¤ä¸åŒ¹é…çš„é”®
    state_dict = checkpoint['model_state_dict']
    model_dict = model.state_dict()
    
    # è¿‡æ»¤ï¼šåªä¿ç•™å½¢çŠ¶åŒ¹é…çš„é”®
    filtered_state_dict = {}
    for k, v in state_dict.items():
        if k in model_dict:
            if v.shape == model_dict[k].shape:
                filtered_state_dict[k] = v
            else:
                print(f"  âš ï¸  Shape mismatch for {k}: checkpoint{v.shape} vs model{model_dict[k].shape}")
    
    # æ£€æµ‹ä¸åŒ¹é…çš„é”®
    unexpected_keys = set(state_dict.keys()) - set(model_dict.keys())
    missing_keys = set(model_dict.keys()) - set(filtered_state_dict.keys())
    
    # æŠ¥å‘Šä¸åŒ¹é…æƒ…å†µ
    if unexpected_keys:
        print(f"\n  â„¹ï¸  Ignoring {len(unexpected_keys)} unexpected keys from checkpoint:")
        for key in sorted(list(unexpected_keys)[:5]):
            print(f"      - {key}")
        if len(unexpected_keys) > 5:
            print(f"      ... and {len(unexpected_keys) - 5} more")
        print(f"  âœ“ These keys are from training components not needed for inference")
    
    if missing_keys:
        print(f"\n  âš ï¸  Warning: {len(missing_keys)} model parameters not found in checkpoint")
        print(f"      These will use random initialization:")
        for key in sorted(list(missing_keys)[:3]):
            print(f"      - {key}")
        if len(missing_keys) > 3:
            print(f"      ... and {len(missing_keys) - 3} more")
    
    # åŠ è½½æƒé‡ï¼ˆéžä¸¥æ ¼æ¨¡å¼ï¼‰
    model.load_state_dict(filtered_state_dict, strict=False)
    model.eval()
    
    print(f"\n  âœ… Model loaded successfully")
    print(f"      - Loaded parameters: {len(filtered_state_dict)}/{len(model_dict)}")
    print(f"      - Ready for inference\n")
    
    return model, checkpoint


def preprocess_image(image_path):
    """
    é¢„å¤„ç†å•å¼ å›¾åƒ
    
    Args:
        image_path: å›¾åƒè·¯å¾„
    
    Returns:
        img_tensor: é¢„å¤„ç†åŽçš„å›¾åƒå¼ é‡ [1, 3, 224, 224]
    """
    # CLIPæ ‡å‡†é¢„å¤„ç†
    transform = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(
            mean=[0.48145466, 0.4578275, 0.40821073],
            std=[0.26862954, 0.26130258, 0.27577711]
        )
    ])
    
    try:
        img = Image.open(image_path).convert('RGB')
        img_tensor = transform(img).unsqueeze(0)  # [1, 3, 224, 224]
        return img_tensor
    except Exception as e:
        raise RuntimeError(f"Failed to load image: {e}")


def predict(model, image_tensor, device):
    """
    é¢„æµ‹å•å¼ å›¾åƒ
    
    Args:
        model: è®­ç»ƒå¥½çš„æ¨¡åž‹
        image_tensor: é¢„å¤„ç†åŽçš„å›¾åƒ [1, 3, 224, 224]
        device: è®¾å¤‡
    
    Returns:
        result_dict: åŒ…å«é¢„æµ‹ç»“æžœçš„å­—å…¸
    """
    with torch.no_grad():
        image_tensor = image_tensor.to(device)
        
        # å‰å‘ä¼ æ’­
        logits = model(image_tensor)  # [1, 2]
        
        # è®¡ç®—æ¦‚çŽ‡
        probs = F.softmax(logits, dim=1)  # [1, 2]
        
        # æå–ç»“æžœ
        real_prob = probs[0, 0].item()
        fake_prob = probs[0, 1].item()
        
        # é¢„æµ‹ç±»åˆ«
        pred_class = torch.argmax(probs, dim=1).item()
        pred_label = "FAKE" if pred_class == 1 else "REAL"
        
        # ç½®ä¿¡åº¦ï¼ˆé¢„æµ‹ç±»åˆ«çš„æ¦‚çŽ‡ï¼‰
        confidence = fake_prob if pred_class == 1 else real_prob
    
    result_dict = {
        'prediction': pred_label,
        'confidence': confidence,
        'real_prob': real_prob,
        'fake_prob': fake_prob,
        'pred_class': pred_class,
        'logits': logits[0].cpu().numpy()
    }
    
    return result_dict


def get_image_files(input_path, recursive=False):
    """
    èŽ·å–æ‰€æœ‰å›¾åƒæ–‡ä»¶
    
    Args:
        input_path: è¾“å…¥è·¯å¾„ï¼ˆæ–‡ä»¶æˆ–æ–‡ä»¶å¤¹ï¼‰
        recursive: æ˜¯å¦é€’å½’æœç´¢å­ç›®å½•
    
    Returns:
        list: å›¾åƒæ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    valid_extensions = {'.jpg', '.jpeg', '.png', '.bmp', '.tiff', '.tif', '.webp', 
                       '.JPG', '.JPEG', '.PNG', '.BMP', '.TIFF', '.TIF', '.WEBP'}
    
    input_path = Path(input_path)
    
    if input_path.is_file():
        # å•ä¸ªæ–‡ä»¶
        if input_path.suffix in valid_extensions:
            return [str(input_path)]
        else:
            raise ValueError(f"File is not a valid image: {input_path}")
    
    elif input_path.is_dir():
        # æ–‡ä»¶å¤¹
        image_files = []
        
        if recursive:
            # é€’å½’æœç´¢æ‰€æœ‰å­ç›®å½•
            for ext in valid_extensions:
                image_files.extend(input_path.rglob(f'*{ext}'))
        else:
            # åªæœç´¢å½“å‰ç›®å½•
            for ext in valid_extensions:
                image_files.extend(input_path.glob(f'*{ext}'))
        
        return sorted([str(f) for f in image_files])
    
    else:
        raise ValueError(f"Invalid input path: {input_path}")


def print_single_result(result, image_path):
    """æ‰“å°å•å¼ å›¾åƒçš„è¯¦ç»†ç»“æžœ"""
    print("\n" + "="*70)
    print("Prediction Results")
    print("="*70)
    print(f"Image:       {os.path.basename(image_path)}")
    print(f"Prediction:  {result['prediction']}")
    print(f"Confidence:  {result['confidence']:.2%}")
    print(f"\nProbabilities:")
    print(f"  Real: {result['real_prob']:.4f} ({result['real_prob']*100:.2f}%)")
    print(f"  Fake: {result['fake_prob']:.4f} ({result['fake_prob']*100:.2f}%)")
    print(f"\nRaw Logits:")
    print(f"  [Real: {result['logits'][0]:.4f}, Fake: {result['logits'][1]:.4f}]")
    
    # å¯ä¿¡åº¦è¯„ä¼°
    if result['confidence'] >= 0.9:
        confidence_level = "Very High"
        emoji = "ðŸŸ¢"
    elif result['confidence'] >= 0.75:
        confidence_level = "High"
        emoji = "ðŸŸ¡"
    elif result['confidence'] >= 0.6:
        confidence_level = "Medium"
        emoji = "ðŸŸ "
    else:
        confidence_level = "Low"
        emoji = "ðŸ”´"
    
    print(f"\nConfidence Level: {emoji} {confidence_level}")
    
    if result['confidence'] < 0.6:
        print("\nâš ï¸  Warning: Low confidence prediction. The model is uncertain about this image.")
    
    print("="*70 + "\n")


def save_detailed_result(result, image_path, output_dir):
    """ä¿å­˜å•å¼ å›¾åƒçš„è¯¦ç»†ç»“æžœåˆ°æ–‡æœ¬æ–‡ä»¶"""
    output_file = os.path.join(output_dir, f"{Path(image_path).stem}_result.txt")
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write("="*70 + "\n")
        f.write("C2P + SVD Detector - Prediction Results\n")
        f.write("="*70 + "\n\n")
        f.write(f"Image:       {os.path.basename(image_path)}\n")
        f.write(f"Full Path:   {image_path}\n")
        f.write(f"Prediction:  {result['prediction']}\n")
        f.write(f"Confidence:  {result['confidence']:.2%}\n\n")
        f.write("Probabilities:\n")
        f.write(f"  Real: {result['real_prob']:.4f} ({result['real_prob']*100:.2f}%)\n")
        f.write(f"  Fake: {result['fake_prob']:.4f} ({result['fake_prob']*100:.2f}%)\n\n")
        f.write("Raw Logits:\n")
        f.write(f"  [Real: {result['logits'][0]:.4f}, Fake: {result['logits'][1]:.4f}]\n")
        f.write("="*70 + "\n")


def main():
    args = parse_args()
    
    print("\n" + "="*70)
    print("C2P + SVD Detector - Inference Mode (NO TEXT GUIDANCE)")
    print("="*70)
    
    # æ£€æŸ¥è®¾å¤‡
    if args.device == 'cuda' and not torch.cuda.is_available():
        print("\nâš ï¸  CUDA not available, switching to CPU")
        args.device = 'cpu'
    
    print(f"\nðŸ“± Using device: {args.device}")
    
    # åŠ è½½æ¨¡åž‹
    try:
        model, checkpoint = load_model(args.checkpoint, args.svd_rank, args.device)
    except Exception as e:
        print(f"\nâŒ Failed to load model: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # èŽ·å–å›¾åƒæ–‡ä»¶åˆ—è¡¨
    print(f"ðŸ” Scanning input: {args.input}")
    try:
        image_files = get_image_files(args.input, recursive=args.recursive)
    except Exception as e:
        print(f"\nâŒ Failed to get image files: {e}")
        return
    
    if not image_files:
        print("âŒ No valid images found!")
        return
    
    num_images = len(image_files)
    print(f"  âœ“ Found {num_images} image(s)")
    
    # åˆ¤æ–­æ˜¯å•å›¾åƒè¿˜æ˜¯æ‰¹é‡
    is_batch = num_images > 1
    
    # å‡†å¤‡è¾“å‡ºè·¯å¾„
    if args.output is None:
        if is_batch:
            # æ‰¹é‡ï¼šè‡ªåŠ¨ç”ŸæˆCSVæ–‡ä»¶å
            input_name = Path(args.input).name
            timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
            args.output = f"predictions_{input_name}_{timestamp}.csv"
        else:
            # å•å›¾ï¼šä¸éœ€è¦CSV
            args.output = None
    
    # åˆ›å»ºè¯¦ç»†ç»“æžœè¾“å‡ºç›®å½•ï¼ˆå¦‚æžœéœ€è¦ï¼‰
    detail_output_dir = None
    if args.save_details and is_batch:
        detail_output_dir = f"detailed_results_{Path(args.input).name}"
        os.makedirs(detail_output_dir, exist_ok=True)
        print(f"  âœ“ Detailed results will be saved to: {detail_output_dir}")
    
    # æ‰¹é‡æŽ¨ç†
    results = []
    errors = []
    
    print(f"\nðŸš€ Starting inference on {num_images} image(s)...\n")
    
    # ä½¿ç”¨è¿›åº¦æ¡ï¼ˆæ‰¹é‡æ¨¡å¼ï¼‰æˆ–ç®€å•å¤„ç†ï¼ˆå•å›¾æ¨¡å¼ï¼‰
    iterator = tqdm(image_files, desc="Processing", unit="img") if is_batch else image_files
    
    for img_path in iterator:
        try:
            # é¢„å¤„ç†
            img_tensor = preprocess_image(img_path)
            
            # é¢„æµ‹
            result = predict(model, img_tensor, args.device)
            
            # è®°å½•ç»“æžœ
            results.append({
                'image_path': img_path,
                'filename': os.path.basename(img_path),
                'prediction': result['prediction'],
                'confidence': result['confidence'],
                'real_prob': result['real_prob'],
                'fake_prob': result['fake_prob'],
                'logit_real': result['logits'][0],
                'logit_fake': result['logits'][1]
            })
            
            # å•å›¾åƒæ¨¡å¼ï¼šç›´æŽ¥æ‰“å°è¯¦ç»†ç»“æžœ
            if not is_batch:
                print_single_result(result, img_path)
            
            # ä¿å­˜è¯¦ç»†ç»“æžœï¼ˆå¦‚æžœå¯ç”¨ï¼‰
            if args.save_details and detail_output_dir:
                save_detailed_result(result, img_path, detail_output_dir)
            
        except Exception as e:
            error_msg = f"{os.path.basename(img_path)}: {str(e)}"
            errors.append({'image': img_path, 'error': str(e)})
            if not is_batch:
                print(f"\nâŒ Failed to process image: {error_msg}")
            else:
                # æ‰¹é‡æ¨¡å¼ä¸‹æ›´æ–°è¿›åº¦æ¡æè¿°
                if isinstance(iterator, tqdm):
                    iterator.set_postfix_str(f"Error: {os.path.basename(img_path)[:20]}")
    
    # æ‰¹é‡æ¨¡å¼ï¼šä¿å­˜CSVå¹¶æ‰“å°ç»Ÿè®¡
    if is_batch and results:
        # ä¿å­˜CSV
        df = pd.DataFrame(results)
        df.to_csv(args.output, index=False)
        print(f"\nâœ… Results saved to: {args.output}")
        
        # ç»Ÿè®¡ä¿¡æ¯
        print("\n" + "="*70)
        print("ðŸ“Š Summary Statistics")
        print("="*70)
        print(f"Total images processed: {len(results)}")
        
        num_real = sum(df['prediction'] == 'REAL')
        num_fake = sum(df['prediction'] == 'FAKE')
        
        print(f"Predicted REAL:         {num_real} ({num_real/len(results)*100:.1f}%)")
        print(f"Predicted FAKE:         {num_fake} ({num_fake/len(results)*100:.1f}%)")
        
        print(f"\nConfidence Statistics:")
        print(f"  Mean:    {df['confidence'].mean():.2%}")
        print(f"  Median:  {df['confidence'].median():.2%}")
        print(f"  Std:     {df['confidence'].std():.2%}")
        print(f"  Min:     {df['confidence'].min():.2%}")
        print(f"  Max:     {df['confidence'].max():.2%}")
        
        # ç½®ä¿¡åº¦åˆ†å¸ƒ
        high_conf = sum(df['confidence'] >= 0.9)
        med_conf = sum((df['confidence'] >= 0.6) & (df['confidence'] < 0.9))
        low_conf = sum(df['confidence'] < 0.6)
        
        print(f"\nConfidence Distribution:")
        print(f"  ðŸŸ¢ Very High (â‰¥90%): {high_conf} ({high_conf/len(results)*100:.1f}%)")
        print(f"  ðŸŸ¡ Medium (60-90%):  {med_conf} ({med_conf/len(results)*100:.1f}%)")
        print(f"  ðŸ”´ Low (<60%):       {low_conf} ({low_conf/len(results)*100:.1f}%)")
        
        # åˆ†ç±»ç»Ÿè®¡
        if num_real > 0:
            real_avg_conf = df[df['prediction'] == 'REAL']['confidence'].mean()
            print(f"\nREAL predictions avg confidence: {real_avg_conf:.2%}")
        if num_fake > 0:
            fake_avg_conf = df[df['prediction'] == 'FAKE']['confidence'].mean()
            print(f"FAKE predictions avg confidence: {fake_avg_conf:.2%}")
        
        print("="*70 + "\n")
    
    # é”™è¯¯æŠ¥å‘Š
    if errors:
        print(f"âš ï¸  Failed to process {len(errors)} image(s):")
        for err in errors[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ªé”™è¯¯
            print(f"  - {os.path.basename(err['image'])}: {err['error']}")
        if len(errors) > 10:
            print(f"  ... and {len(errors) - 10} more errors")
        print()
    
    # æœ€ç»ˆæ€»ç»“
    if results:
        success_rate = len(results) / (len(results) + len(errors)) * 100
        print(f"âœ… Successfully processed {len(results)}/{len(results) + len(errors)} images ({success_rate:.1f}%)\n")


if __name__ == '__main__':
    main()
