"""
Dataset for Deepfake Detection
æ”¯æŒä¸¤ç§æ¨¡å¼ï¼š
1. JSONæ ‡æ³¨æ–‡ä»¶æ¨¡å¼ï¼ˆæ¨èï¼‰
2. æ–‡ä»¶å¤¹ç»“æ„æ¨¡å¼ï¼ˆå…¼å®¹æ—§ä»£ç ï¼‰

æ–‡ä»¶å¤¹ç»“æ„ï¼š
root_dir/
  â”œâ”€â”€ train/
  â”‚   â”œâ”€â”€ folder_01/
  â”‚   â”‚   â”œâ”€â”€ 0_real/
  â”‚   â”‚   â”‚   â””â”€â”€ *.jpg
  â”‚   â”‚   â””â”€â”€ 1_fake/
  â”‚   â”‚       â””â”€â”€ *.jpg
  â”‚   â”œâ”€â”€ folder_02/
  â”‚   â””â”€â”€ ...
  â””â”€â”€ val/
      â””â”€â”€ (åŒtrainç»“æ„)
"""

import os
import json
from pathlib import Path
from PIL import Image
import torch
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms


class DeepfakeDataset(Dataset):
    """
    æ·±åº¦ä¼ªé€ æ£€æµ‹æ•°æ®é›†
    æ”¯æŒJSONæ ‡æ³¨å’Œæ–‡ä»¶å¤¹ç»“æ„ä¸¤ç§æ¨¡å¼
    """
    
    def __init__(
        self, 
        data_root,
        json_path=None,      # æ–°å¢ï¼šJSONæ ‡æ³¨æ–‡ä»¶è·¯å¾„
        split='train',       # å¦‚æœä¸ç”¨JSONï¼ŒæŒ‡å®šsplit
        transform=None,
        caption_root=None,
        mode='json'          # 'json' æˆ– 'folder'
    ):
        """
        Args:
            data_root: æ•°æ®æ ¹ç›®å½• (ä¾‹å¦‚ D:/svd-c2p/xunlian)
            json_path: JSONæ ‡æ³¨æ–‡ä»¶è·¯å¾„ (æ¨èæ¨¡å¼)
            split: 'train' æˆ– 'val' (ä»…åœ¨folderæ¨¡å¼ä¸‹ä½¿ç”¨)
            transform: å›¾åƒå˜æ¢
            caption_root: Captionæ–‡æœ¬æ ¹ç›®å½• (å¯é€‰)
            mode: 'json' (ä»JSONåŠ è½½) æˆ– 'folder' (æ‰«ææ–‡ä»¶å¤¹)
        """
        self.data_root = Path(data_root)
        self.caption_root = Path(caption_root) if caption_root else None
        self.transform = transform
        self.mode = mode
        
        self.samples = []
        
        # æ ¹æ®æ¨¡å¼æ„å»ºæ•°æ®é›†
        if mode == 'json' and json_path:
            self._load_from_json(json_path)
        elif mode == 'folder':
            self._load_from_folder(split)
        else:
            raise ValueError(f"Invalid mode '{mode}' or missing json_path")
        
        print(f"âœ“ Loaded {len(self.samples)} samples")
        self._print_stats()
    
    def _load_from_json(self, json_path):
        """
        ä»JSONæ ‡æ³¨æ–‡ä»¶åŠ è½½æ•°æ®
        
        JSONæ ¼å¼:
        [
            {
                "image_path": "train/folder_01/0_real/img.jpg",
                "label": 0,
                "label_name": "real"
            },
            ...
        ]
        """
        print(f"\nLoading dataset from JSON: {json_path}")
        
        json_path = Path(json_path)
        if not json_path.exists():
            raise FileNotFoundError(f"JSON file not found: {json_path}")
        
        with open(json_path, 'r', encoding='utf-8') as f:
            data_list = json.load(f)
        
        for item in data_list:
            # å›¾åƒè·¯å¾„ï¼ˆç›¸å¯¹äºdata_rootï¼‰
            img_relative_path = item['image_path']
            img_full_path = self.data_root / img_relative_path
            
            # Captionè·¯å¾„ï¼ˆå¦‚æœæœ‰ï¼‰
            caption_path = None
            if self.caption_root:
                caption_relative = Path(img_relative_path).with_suffix('.txt')
                caption_path = self.caption_root / caption_relative
            
            self.samples.append({
                'image_path': str(img_full_path),
                'label': item['label'],  # 0 or 1
                'label_name': item.get('label_name', 'unknown'),
                'caption_path': str(caption_path) if caption_path else None
            })
    
    def _load_from_folder(self, split):
        """
        ä»æ–‡ä»¶å¤¹ç»“æ„åŠ è½½æ•°æ®
        
        ç»“æ„ï¼šroot_dir/split/folderX/0_real or 1_fake/*.jpg
        """
        print(f"\nScanning folder structure: {self.data_root / split}")
        
        split_dir = self.data_root / split
        
        if not split_dir.exists():
            raise FileNotFoundError(f"Split directory not found: {split_dir}")
        
        # éå†æ‰€æœ‰å­æ–‡ä»¶å¤¹
        for folder in sorted(split_dir.iterdir()):
            if not folder.is_dir():
                continue
            
            # æ£€æŸ¥ 0_real å’Œ 1_fake
            for class_folder in ['0_real', '1_fake']:
                class_path = folder / class_folder
                
                if not class_path.exists():
                    continue
                
                label = 0 if class_folder == '0_real' else 1
                label_name = 'real' if label == 0 else 'fake'
                
                # éå†å›¾åƒæ–‡ä»¶
                for img_file in sorted(class_path.glob('*')):
                    if img_file.suffix.lower() not in ['.jpg', '.jpeg', '.png', '.bmp', '.webp']:
                        continue
                    
                    # Captionè·¯å¾„
                    caption_path = None
                    if self.caption_root:
                        relative_path = img_file.relative_to(self.data_root)
                        caption_path = self.caption_root / relative_path.with_suffix('.txt')
                    
                    self.samples.append({
                        'image_path': str(img_file),
                        'label': label,
                        'label_name': label_name,
                        'caption_path': str(caption_path) if caption_path else None
                    })
    
    def _print_stats(self):
        """æ‰“å°æ•°æ®é›†ç»Ÿè®¡ä¿¡æ¯"""
        num_real = sum(1 for s in self.samples if s['label'] == 0)
        num_fake = len(self.samples) - num_real
        
        print(f"  - Real: {num_real}")
        print(f"  - Fake: {num_fake}")
        
        # â˜… ä¿®å¤é™¤é›¶é”™è¯¯
        total = num_real + num_fake
        if total > 0:
            print(f"  - Balance: {num_real/total*100:.1f}% real")
        else:
            print(f"  - Balance: N/A (empty dataset)")
    
    def __len__(self):
        return len(self.samples)
    
    def __getitem__(self, idx):
        """
        Returns:
            image: [3, 224, 224], è½¬æ¢åçš„å›¾åƒå¼ é‡
            label: int, 0 (real) or 1 (fake)
            text: str, æ–‡æœ¬æè¿°ï¼ˆlabel + captionï¼‰
        """
        sample = self.samples[idx]
        
        # ========== 1. åŠ è½½å›¾åƒ ==========
        try:
            image = Image.open(sample['image_path']).convert('RGB')
        except Exception as e:
            print(f"âš  Error loading {sample['image_path']}: {e}")
            # è¿”å›é»‘è‰²å›¾åƒä½œä¸ºfallback
            image = Image.new('RGB', (224, 224), color=(0, 0, 0))
        
        # åº”ç”¨å˜æ¢
        if self.transform:
            image = self.transform(image)
        
        # ========== 2. è·å–æ ‡ç­¾ ==========
        label = sample['label']
        
        # ========== 3. æ„å»ºæ–‡æœ¬æè¿° ==========
        # åŸºç¡€labelæ–‡æœ¬
        label_text = "a photo of a real face" if label == 0 else "a photo of a fake face"
        
        # åŠ è½½captionï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        caption_text = ""
        if sample['caption_path'] and os.path.exists(sample['caption_path']):
            try:
                with open(sample['caption_path'], 'r', encoding='utf-8') as f:
                    caption_text = f.read().strip()
            except Exception as e:
                caption_text = ""
        
        # ç»„åˆæœ€ç»ˆæ–‡æœ¬
        if caption_text:
            full_text = f"{label_text}. {caption_text}"
        else:
            full_text = label_text
        
        return image, label, full_text


def get_transforms(mode='train', resolution=224):
    """
    è·å–æ•°æ®å˜æ¢
    
    Args:
        mode: 'train' æˆ– 'test'
        resolution: ç›®æ ‡åˆ†è¾¨ç‡
    
    Returns:
        torchvision.transforms.Compose
    """
    # CLIPå®˜æ–¹å½’ä¸€åŒ–å‚æ•°
    mean = [0.48145466, 0.4578275, 0.40821073]
    std = [0.26862954, 0.26130258, 0.27577711]
    
    if mode == 'train':
        return transforms.Compose([
            transforms.Resize((resolution, resolution)),
            transforms.RandomHorizontalFlip(p=0.5),
            transforms.RandomRotation(10),
            transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std)
        ])
    else:  # test/val
        return transforms.Compose([
            transforms.Resize((resolution, resolution)),
            transforms.ToTensor(),
            transforms.Normalize(mean=mean, std=std)
        ])


def create_dataloaders(
    data_root,
    train_json=None,
    val_json=None,
    caption_root=None,
    batch_size=32,
    num_workers=4,
    mode='json'
):
    """
    åˆ›å»ºè®­ç»ƒå’ŒéªŒè¯æ•°æ®åŠ è½½å™¨
    
    Args:
        data_root: æ•°æ®æ ¹ç›®å½•
        train_json: è®­ç»ƒé›†JSONè·¯å¾„ (jsonæ¨¡å¼å¿…éœ€)
        val_json: éªŒè¯é›†JSONè·¯å¾„ (jsonæ¨¡å¼å¿…éœ€)
        caption_root: Captionæ ¹ç›®å½• (å¯é€‰)
        batch_size: æ‰¹é‡å¤§å°
        num_workers: æ•°æ®åŠ è½½çº¿ç¨‹æ•°
        mode: 'json' æˆ– 'folder'
    
    Returns:
        train_loader, val_loader
    """
    
    print("\n" + "="*70)
    print("Creating DataLoaders")
    print("="*70)
    
    # ========== è®­ç»ƒé›† ==========
    if mode == 'json':
        if not train_json:
            raise ValueError("train_json is required in JSON mode")
        
        train_dataset = DeepfakeDataset(
            data_root=data_root,
            json_path=train_json,
            transform=get_transforms(mode='train'),
            caption_root=caption_root,
            mode='json'
        )
    else:
        train_dataset = DeepfakeDataset(
            data_root=data_root,
            split='train',
            transform=get_transforms(mode='train'),
            caption_root=caption_root,
            mode='folder'
        )
    
    # ========== éªŒè¯é›† ==========
    if mode == 'json':
        if not val_json:
            raise ValueError("val_json is required in JSON mode")
        
        val_dataset = DeepfakeDataset(
            data_root=data_root,
            json_path=val_json,
            transform=get_transforms(mode='test'),
            caption_root=caption_root,
            mode='json'
        )
    else:
        val_dataset = DeepfakeDataset(
            data_root=data_root,
            split='val',
            transform=get_transforms(mode='test'),
            caption_root=caption_root,
            mode='folder'
        )
    
    # ========== åˆ›å»ºDataLoader ==========
    train_loader = DataLoader(
        train_dataset,
        batch_size=batch_size,
        shuffle=True,
        num_workers=num_workers,
        pin_memory=True,
        drop_last=True  # è®­ç»ƒæ—¶ä¸¢å¼ƒæœ€åä¸€ä¸ªä¸å®Œæ•´çš„batch
    )
    
    val_loader = DataLoader(
        val_dataset,
        batch_size=batch_size,
        shuffle=False,
        num_workers=num_workers,
        pin_memory=True
    )
    
    print(f"\nâœ“ Train batches: {len(train_loader)}")
    print(f"âœ“ Val batches:   {len(val_loader)}")
    print("="*70 + "\n")
    
    return train_loader, val_loader


# ============================================================
# æµ‹è¯•ä»£ç 
# ============================================================
if __name__ == '__main__':
    print("\n" + "="*70)
    print("Testing DeepfakeDataset")
    print("="*70)
    
    # ========== æµ‹è¯•å‚æ•° ==========
    data_root = r"D:\svd-c2p\xunlian"
    train_json = r"D:\svd-c2p\xunlian\train.json"
    val_json = r"D:\svd-c2p\xunlian\val.json"
    
    # ========== æµ‹è¯•JSONæ¨¡å¼ ==========
    print("\nğŸ”µ Test 1: JSON mode")
    print("-" * 70)
    
    try:
        train_loader, val_loader = create_dataloaders(
            data_root=data_root,
            train_json=train_json,
            val_json=val_json,
            batch_size=4,
            num_workers=0,  # æµ‹è¯•æ—¶ç”¨0é¿å…å¤šè¿›ç¨‹é—®é¢˜
            mode='json'
        )
        
        # æµ‹è¯•åŠ è½½ä¸€ä¸ªbatch
        print("\nLoading a batch from train_loader...")
        for images, labels, texts in train_loader:
            print(f"  âœ“ Images shape: {images.shape}")
            print(f"  âœ“ Labels: {labels.tolist()}")
            print(f"  âœ“ Text samples:")
            for i, text in enumerate(texts[:2]):
                print(f"    [{i}] {text}")
            break
        
        print("\nâœ… JSON mode test passed!")
        
    except Exception as e:
        print(f"\nâŒ JSON mode test failed: {e}")
    
    # ========== æµ‹è¯•Folderæ¨¡å¼ ==========
    print("\nğŸŸ¢ Test 2: Folder mode")
    print("-" * 70)
    
    try:
        folder_root = r"D:\svd-c2p\xunlian"
        
        train_loader, val_loader = create_dataloaders(
            data_root=folder_root,
            batch_size=4,
            num_workers=0,
            mode='folder'
        )
        
        print("\nLoading a batch from train_loader...")
        for images, labels, texts in train_loader:
            print(f"  âœ“ Images shape: {images.shape}")
            print(f"  âœ“ Labels: {labels.tolist()}")
            break
        
        print("\nâœ… Folder mode test passed!")
        
    except Exception as e:
        print(f"\nâŒ Folder mode test failed: {e}")
    
    print("\n" + "="*70)
    print("All tests completed!")
    print("="*70 + "\n")
